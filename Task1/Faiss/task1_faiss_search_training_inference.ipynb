{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMh80KfNSaky"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import faiss\n",
        "from faiss import write_index, IndexFlatL2, IndexIVFFlat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LeihM5bumBS"
      },
      "outputs": [],
      "source": [
        "def load_emb(enc_type):\n",
        "    embs = []\n",
        "    ids = []\n",
        "\n",
        "    if enc_type == 'img':\n",
        "        dir_name = 'emb_tweet'\n",
        "        file_pfx = 'enc_'\n",
        "    else:\n",
        "        dir_name = 'emb_tweet'\n",
        "        file_pfx = f'{enc_type}_'\n",
        "\n",
        "    for file in os.listdir(dir_name):\n",
        "        if file.endswith('.pkl') and file.startswith(file_pfx):\n",
        "            with open(os.path.join(dir_name, file), \"rb\") as f_in:\n",
        "                data = pickle.load(f_in)\n",
        "                embs.extend(data['embeddings'])\n",
        "                ids.extend(data['ids'])\n",
        "\n",
        "    return np.array(embs), ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb12DKM7uqCW"
      },
      "outputs": [],
      "source": [
        "def preprocess(data1, data2, lk):\n",
        "    multimodal = np.concatenate((data1, data2), axis=1)\n",
        "    return multimodal, np.array(lk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtkDe3Hfusvq"
      },
      "outputs": [],
      "source": [
        "def build_index(embeddings):\n",
        "    quantizer = IndexFlatL2(embeddings.shape[1])\n",
        "    nlist = 40\n",
        "    index = IndexIVFFlat(quantizer, embeddings.shape[1], nlist)\n",
        "    index.train(embeddings)\n",
        "    index.add(embeddings)\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkVrPKINuu0V"
      },
      "outputs": [],
      "source": [
        "def calc_error(test, index, train_lk, test_lk, k=15):\n",
        "    \"\"\"\n",
        "    Calculate the Root Mean Squared Error (RMSE) for a set of test embeddings.\n",
        "\n",
        "    Args:\n",
        "    - test (numpy.ndarray): Array of test embeddings.\n",
        "    - index (nmslib.Index): Nearest neighbors index for the training data.\n",
        "    - train_lk (numpy.ndarray): Array of training likes corresponding to the embeddings.\n",
        "    - test_lk (numpy.ndarray): Array of actual likes for the test embeddings.\n",
        "    - k (int): Number of nearest neighbors to consider (default is 15).\n",
        "\n",
        "    Returns:\n",
        "    - float: Root Mean Squared Error (RMSE) between predicted and actual likes.\n",
        "    \"\"\"\n",
        "\n",
        "    # List to store squared errors\n",
        "    sq_err = []\n",
        "\n",
        "    # Iterate over each test embedding\n",
        "    for i, emb in enumerate(test):\n",
        "        # Find the k-nearest neighbors in the training data\n",
        "        D, I = index.search(np.array([emb]), k)\n",
        "\n",
        "        # Extract likes of the nearest neighbors\n",
        "        nearest = [train_lk[idx] for idx in I[0]]\n",
        "        nearest = np.array(nearest)\n",
        "\n",
        "        # Calculate quartiles and interquartile range (IQR) for outlier removal\n",
        "        q1 = np.percentile(nearest, 20)\n",
        "        q3 = np.percentile(nearest, 80)\n",
        "        iqr = q3 - q1\n",
        "        lower = q1 - 1.5 * iqr\n",
        "        upper = q3 + 1.5 * iqr\n",
        "\n",
        "        # Filter out outliers\n",
        "        filt_indices = np.where((nearest >= lower) & (nearest <= upper))[0]\n",
        "        filt_likes = nearest[filt_indices]\n",
        "\n",
        "        # Calculate predicted likes based on filtered neighbors\n",
        "        try:\n",
        "            pred_likes = np.average(filt_likes)\n",
        "        except ZeroDivisionError:\n",
        "            pred_likes = np.mean(filt_likes)\n",
        "\n",
        "        # Actual likes for the test sample\n",
        "        act_likes = test_lk[i]\n",
        "\n",
        "        # Calculate squared error and append to the list\n",
        "        sq_err.append((pred_lik\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAWsxP9JuxL9"
      },
      "outputs": [],
      "source": [
        "embeds1, ids1 = load_emb('img')\n",
        "embeds2, _ = load_emb('txt')\n",
        "likes, _ = load_emb('likes')\n",
        "\n",
        "multimodal, likes = preprocess(embeds1, embeds2, likes)\n",
        "\n",
        "tr_size = int(0.8 * len(multimodal))\n",
        "train = multimodal[:tr_size]\n",
        "test = multimodal[tr_size:]\n",
        "\n",
        "train_likes = likes[:tr_size]\n",
        "test_likes = likes[tr_size:]\n",
        "\n",
        "index = build_index(train)\n",
        "\n",
        "rmse = calc_error(test, index, train_likes, test_likes)\n",
        "print('Final RMSE:', rmse)\n",
        "\n",
        "\n",
        "fin_index = build_index(multimodal)\n",
        "write_index(fin_index, 'mm-ind.index')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
